{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "# Now attempt to load your BERTopic model\n",
    "topic_model = BERTopic.load(\"G:/BERTopic/attachment/models/attach_sentence1_model.pkl\")\n",
    "\n",
    "# Load the DataFrame from the .pkl file\n",
    "with open(\"G:/BERTopic/attachment/models/attach_sentence1_data.pkl\", \"rb\") as file:\n",
    "    df = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standerd BERTopic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "# Load the BERTopic model\n",
    "topic_model = BERTopic.load('G:/BERTopic/attachment/models/attach_sen2_DocTopics_model.pkl')\n",
    "\n",
    "# Load the DataFrame from the csv file\n",
    "with open(, \"rb\") as file:\n",
    "    df = pickle.load(file)\n",
    "\n",
    "docs = df['docs'].tolist()\n",
    "timestamps = df['timestamps'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "with open(model_save_path, \"rb\") as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "with open(data_save_path, \"rb\") as data_file:\n",
    "    loaded_data = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I used the dimensionality reduction technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Struggles with 'dimensionality' when loading the model\n",
    "\n",
    "import pickle\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure this class definition is present or imported before loading the model\n",
    "class Dimensionality:\n",
    "    \"\"\" Use this for pre-calculated reduced embeddings \"\"\"\n",
    "    def __init__(self, reduced_embeddings):\n",
    "        self.reduced_embeddings = reduced_embeddings\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.reduced_embeddings\n",
    "\n",
    "# Now attempt to load your BERTopic model\n",
    "topic_model = BERTopic.load(\"saves/rpg/rpg_score_5_model.pkl\")\n",
    "\n",
    "# Load the DataFrame from the .pkl file\n",
    "with open(\"saves/rpg/rpg_score_5_dataframe.pkl\", \"rb\") as file:\n",
    "    df = pickle.load(file)\n",
    "\n",
    "# Assuming 'docs', 'timestamps', 'topics', 'subreddit', 'id', 'author', and 'score'\n",
    "docs = df['docs'].tolist()\n",
    "timestamps = df['timestamps'].tolist()\n",
    "topics = df['topics'].tolist()\n",
    "subreddit = df['subreddit'].tolist()\n",
    "id = df['id'].tolist()\n",
    "author = df['author'].tolist()\n",
    "score = df['score'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_representative_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_freq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big .txt file for all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "# Extract the results\n",
    "topics = topic_model.get_topics()\n",
    "topic_freq = topic_model.get_topic_freq()\n",
    "topic_info = topic_model.get_topic_info()\n",
    "representative_docs = topic_model.get_representative_docs()\n",
    "\n",
    "# Save the results in a more structured and readable manner\n",
    "with open('G:/BERTopic/attachment/analysis/attach_sentence1.txt', 'w') as f:\n",
    "    # Topics\n",
    "    f.write(\"TOPICS:\\n\")\n",
    "    for topic_num, terms in topics.items():\n",
    "        terms_str = ', '.join([term[0] for term in terms])\n",
    "        f.write(f\"Topic {topic_num}: {terms_str}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    # Topic Frequency\n",
    "    f.write(\"TOPIC FREQUENCY:\\n\")\n",
    "    for index, row in topic_freq.iterrows():\n",
    "        f.write(f\"Topic {row['Topic']}: {row['Count']} entries\\n\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    # Topic Info\n",
    "    f.write(\"TOPIC INFO:\\n\")\n",
    "    for index, row in topic_info.iterrows():\n",
    "        f.write(f\"Topic {row['Topic']}\\n\")\n",
    "        f.write(f\"  - Name: {row['Name']}\\n\")\n",
    "        f.write(\"  - Representation:\\n\")\n",
    "        for term in row['Representation']:\n",
    "            f.write(f\"    * {term}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    # Representative Docs\n",
    "    f.write(\"REPRESENTATIVE DOCS:\\n\")\n",
    "    for topic_num, docs in representative_docs.items():\n",
    "        f.write(f\"Topic {topic_num} representative docs:\\n\")\n",
    "        for doc in docs:\n",
    "            f.write(f\"  - {doc}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV file with all topics and their representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'topic_info' is already defined and includes topic representations\n",
    "csv_file_path = 'G:/BERTopic/attachment/analysis/attach_sentence1.csv'  # Hardcoded save location for CSV\n",
    "\n",
    "# Convert 'topic_info' DataFrame directly to CSV\n",
    "topic_info.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves to csv topic model for specified topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you've already loaded the BERTopic model and have the docs list\n",
    "# Step 1: Get the document info\n",
    "document_info = topic_model.get_document_info(docs)\n",
    "\n",
    "# List of topics you want to extract\n",
    "topics_to_include = [0, 4, 10, 14, 21, 27, 35, 40, 49, 66, 72, 74, 77, 79, 80, 81, 82, 84, 87, 89, 99, 111, 115, 116,\n",
    "               121, 124, 134, 145, 148, 149, 155, 158, 159, 163, 167, 177, 180, 181, 183, 184, 187, 200, 202, 203, 206, 213, \n",
    "               217, 218, 228, 229, 233, 235, 241, 245, 254, 265, 266, 267, 268, 270, 274, 287, 315, 327, \n",
    "               335, 336, 337, 338, 340, 347, 350, 351, 354, 356, 358, 373, 376, 385, 388, 395, 401, 402, 408, 415, 417, 421, 432, 433, 442, 485,\n",
    "               447, 467, 469, 484, 485, 501, 503, 508, 510, 515, 525, 543, 545, 546, 579, 553, 555, 563, 574, 575, 594, 595, 599, \n",
    "               604, 611, 619, 634, 651, 652, 668, 673, 676, 695, 697, 702, 706, 709, 713, 714, 717, 722, 746, 751, 755, 757, 759, 760, 762, 769, 786, 788, \n",
    "               793, 801, 806, 812, 817, 822, 823, 830, 844, 846, 847, 863, 873, 891, 892, 895, 902, 908, 912, 914, 916, 921, 923, 930, 936]\n",
    "\n",
    "# Step 2: Filter the DataFrame by the given set of topics\n",
    "filtered_df = document_info[document_info['Topic'].isin(topics_to_include)]\n",
    "\n",
    "# Step 3: Select only the relevant columns\n",
    "selected_df = filtered_df[['Document', 'Topic', 'Probability', 'Representation']]\n",
    "\n",
    "# Step 4: Save the selected DataFrame to a .csv file with all documents\n",
    "selected_df.to_csv(\"C:/Projects/BERTopic/analysis/rpg/documents_all.csv\", index=False)\n",
    "\n",
    "# Step 5: Create a DataFrame with only 200 documents for each topic\n",
    "limited_df = pd.concat([filtered_df[filtered_df['Topic'] == topic].sample(min(len(filtered_df[filtered_df['Topic'] == topic]), 200)) \n",
    "                        for topic in topics_to_include])\n",
    "\n",
    "# Step 6: Save the limited DataFrame to a .csv file with only 200 documents per topic\n",
    "limited_df.to_csv(\"C:/Projects/BERTopic/analysis/rpg/documents_limited.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, similarity = topic_model.find_topics(\"Overcoming or dealing with anxiety\", top_n=5)\n",
    "for topic, score in zip(topics, similarity):\n",
    "    print(f\"Topic {topic} (Similarity: {score:.4f}): {topic_model.get_topic(topic)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_relevant_topics_to_file(topic_model, search_terms, filename, top_n=5):\n",
    "    \"\"\"\n",
    "    Find and save topics related to a list of search terms to a .txt file, \n",
    "    along with representative documents for the topics.\n",
    "\n",
    "    Parameters:\n",
    "    - topic_model: The trained BERTopic model.\n",
    "    - search_terms: A list of search terms/phrases related to the desired topics.\n",
    "    - filename: Name of the .txt file to save the results.\n",
    "    - top_n: Number of top similar topics to retrieve for each search term.\n",
    "\n",
    "    Returns:\n",
    "    - None (writes the relevant topics, their terms, and representative docs to a .txt file)\n",
    "    \"\"\"\n",
    "    \n",
    "    topics_covered = set()  # To keep track of topics we've added representative docs for\n",
    "    all_relevant_topics = set()  # To gather all unique topics from the search results\n",
    "    \n",
    "    with open(filename, 'w') as file:\n",
    "        # Display search terms and their related topics at the top\n",
    "        for term in search_terms:\n",
    "            file.write(f\"Searching for topics related to: '{term}'\\n\\n\")\n",
    "            topics, similarity = topic_model.find_topics(term, top_n=top_n)\n",
    "            for topic, score in zip(topics, similarity):\n",
    "                file.write(f\"Topic {topic} (Similarity: {score:.4f})\\n\")\n",
    "                all_relevant_topics.add(topic)  # Add topic to the set\n",
    "            file.write(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "        \n",
    "        # Append topic details and representative documents at the end in numerical order\n",
    "        for topic in sorted(all_relevant_topics):  # Sort topics numerically\n",
    "            if topic not in topics_covered:\n",
    "                topic_terms = topic_model.get_topic(topic)\n",
    "                formatted_terms = ', '.join([f\"{word[0]} ({word[1]:.4f})\" for word in topic_terms])\n",
    "                file.write(f\"\\nTopic {topic} Details: {formatted_terms}\\n\\n\")\n",
    "                \n",
    "                reps = topic_model.get_representative_docs(topic)\n",
    "                file.write(f\"Representative Documents for Topic {topic}:\\n\")\n",
    "                for doc in reps:\n",
    "                    file.write(\"\\n\" + \"-\" * 30 + \"\\n\")\n",
    "                    file.write(f\"{doc}\\n\")\n",
    "                    file.write(\"-\" * 30 + \"\\n\")\n",
    "                topics_covered.add(topic)\n",
    "                file.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "# Revised list of search terms related to feelings of loneliness and isolation\n",
    "search_terms = [\n",
    "    \"Sadness\",\n",
    "    \"Fear\",\n",
    "    \"Disgust\",\n",
    "    \"Identity\",\n",
    "    \"Self\",\n",
    "    \"Ego\",\n",
    "    \"Self-worth\",\n",
    "    \"Confidence\",\n",
    "    \"Self-esteem\",\n",
    "    \"Belonging\",\n",
    "    \"Connection\",\n",
    "    \"Attachment\",\n",
    "    \"Intimacy\",\n",
    "    \"Affection\",\n",
    "    \"Cohesion\",\n",
    "    \"Relationship\",\n",
    "    \"Wellbeing\",\n",
    "    \"Mental health\",\n",
    "    \"Mindfulness\",\n",
    "    \"Resilience\",\n",
    "    \"Coping\",\n",
    "    \"Therapy\",\n",
    "    \"Healing\",\n",
    "    \"Recovery\",\n",
    "    \"Empowerment\",\n",
    "    \"Acceptance\",\n",
    "    \"Validation\",\n",
    "    \"Support\",\n",
    "    \"Empathy\",\n",
    "    \"Compassion\"\n",
    "]\n",
    "\n",
    "# Use the function to explore the relevant topics and save to a .txt file\n",
    "filename = \"C:/Projects/BERTopic/analysis/rpg/rpg_score_5_connection.txt\"\n",
    "explore_relevant_topics_to_file(topic_model, search_terms, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_topics()\n",
    "fig.write_html(\"analysis/rpg/visualize_topics.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "tree = topic_model.get_topic_tree(hierarchial_topics)\n",
    "print(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "topic_model = BERTopic.load(\"saves/rpg/verify_model\", embedding_model=\"thenlper/gte-base\")\n",
    "\n",
    "# Load the DataFrame from the .pkl file\n",
    "with open(\"saves/rpg/verify_docssave.pkl\", \"rb\") as file:\n",
    "    df = pickle.load(file)\n",
    "\n",
    "docs = df['docs'].tolist()\n",
    "timestamps = df['timestamps'].tolist()\n",
    "\n",
    "topics_over_time = topic_model.topics_over_time(docs, timestamps, nr_bins=10)\n",
    "topic_model.visualize_topics_over_time(topics_over_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the topics_over_time DataFrame\n",
    "topics_over_time = topic_model.topics_over_time(docs, timestamps, nr_bins=15)\n",
    "\n",
    "# List of topic IDs you want to visualize\n",
    "selected_topics = ([769, 124, 53, 149, 194, 83, 121, 89, 80, 21, 260, 184, 863, 218, 415, 717])\n",
    "\n",
    "# Filter the DataFrame to include only the selected topics\n",
    "filtered_topics_over_time = topics_over_time[topics_over_time['Topic'].isin(selected_topics)]\n",
    "\n",
    "# Visualize the filtered topics over time\n",
    "topic_model.visualize_topics_over_time(filtered_topics_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "# Visualize the filtered topics over time and capture the figure\n",
    "fig = topic_model.visualize_topics_over_time(filtered_topics_over_time)\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "pio.write_html(fig, file='topics_over_time.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
