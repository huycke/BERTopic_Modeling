{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16b270e",
   "metadata": {},
   "source": [
    "## Notebook 01: Data Preprocessing\n",
    "\n",
    "This notebook uses the `load_and_preprocess_data` function from `src.preprocessing` to load raw data, apply cleaning and filtering, and save the processed output.\n",
    "\n",
    "**Target Data:** Semantic Scholar data (combining 'title' and 'abstract')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b54f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added g:\\BERTopic_Modeling to sys.path\n",
      "Successfully imported 'load_and_preprocess_data' from src.preprocessing\n"
     ]
    }
   ],
   "source": [
    "# ## 1. Imports and Setup\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# --- Add src directory to Python path ---\n",
    "# This allows importing modules from src. Adjust path if notebook is moved.\n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    print(f\"Added {module_path} to sys.path\")\n",
    "else:\n",
    "    print(f\"{module_path} already in sys.path\")\n",
    "\n",
    "# --- Import the preprocessing function ---\n",
    "try:\n",
    "    from src.preprocessing import load_and_preprocess_data \n",
    "    print(\"Successfully imported 'load_and_preprocess_data' from src.preprocessing\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing functions: {e}\")\n",
    "    print(\"Ensure the 'src' directory is in the Python path and preprocessing.py exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during import: {e}\")\n",
    "\n",
    "# --- Configure Logging ---\n",
    "# Basic logging setup for notebook visibility\n",
    "# Use force=True to allow reconfiguring logging in Jupyter environment\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07fc4ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 11:18:36,916 - INFO - Successfully loaded configuration from: g:\\BERTopic_Modeling\\configs\\reddit_config.yaml\n",
      "2025-07-28 11:18:36,917 - INFO - Successfully loaded configuration from g:\\BERTopic_Modeling\\configs\\reddit_config.yaml\n",
      "2025-07-28 11:18:36,917 - INFO - Raw data file path: g:\\BERTopic_Modeling\\data/raw/IFS_test.csv\n",
      "2025-07-28 11:18:36,918 - INFO - Processed data output file path: g:\\BERTopic_Modeling\\data/processed/IFS_test_processed.csv\n",
      "2025-07-28 11:18:36,918 - INFO - Dropped rows output file path: g:\\BERTopic_Modeling\\data/processed/IFS_test_dropped.csv\n"
     ]
    }
   ],
   "source": [
    "# ## 2. Load Configuration from YAML file\n",
    "\n",
    "from src.utils import load_config\n",
    "\n",
    "# --- Define paths ---\n",
    "project_root_dir = os.path.abspath(os.path.join('..'))\n",
    "config_path = os.path.join(project_root_dir, 'configs', 'reddit_config.yaml')\n",
    "\n",
    "# --- Load configuration ---\n",
    "try:\n",
    "    config = load_config(config_path)\n",
    "    logging.info(f\"Successfully loaded configuration from {config_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(e)\n",
    "    config = None\n",
    "except Exception as e:\n",
    "    logging.error(f\"An unexpected error occurred: {e}\")\n",
    "    config = None\n",
    "\n",
    "if config:\n",
    "    # --- Resolve relative paths to absolute paths ---\n",
    "    # This makes the script runnable from any directory\n",
    "    config['paths']['raw_data_file'] = os.path.join(project_root_dir, config['paths']['raw_data_file'])\n",
    "    config['paths']['processed_data_output_file'] = os.path.join(project_root_dir, config['paths']['processed_data_output_file'])\n",
    "    config['paths']['dropped_rows_output_file'] = os.path.join(project_root_dir, config['paths']['dropped_rows_output_file'])\n",
    "\n",
    "    logging.info(f\"Raw data file path: {config['paths']['raw_data_file']}\")\n",
    "    logging.info(f\"Processed data output file path: {config['paths']['processed_data_output_file']}\")\n",
    "    logging.info(f\"Dropped rows output file path: {config['paths']['dropped_rows_output_file']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1bc2a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 11:29:53,795 - INFO - Attempting to load and preprocess data from: g:\\BERTopic_Modeling\\data/raw/IFS_test.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing for: g:\\BERTopic_Modeling\\data/raw/IFS_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 11:29:54,380 - INFO - Preprocessing finished. Processed DataFrame shape: (112156, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (112156, 12)\n",
      "Checking for missing values in required columns: ['selftext']\n",
      "Warning: Required column 'selftext' not found in DataFrame. Skipping this check for this column.\n",
      "No rows dropped due to missing/empty values in required columns.\n",
      "Error: Text source columns ['title', 'selftext'] not found in the (potentially filtered) DataFrame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 11:29:55,059 - INFO - Processed DataFrame saved to: g:\\BERTopic_Modeling\\data/processed/IFS_test_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# ## 3. Run Preprocessing\n",
    "\n",
    "if config:\n",
    "    logging.info(f\"Attempting to load and preprocess data from: {config['paths']['raw_data_file']}\")\n",
    "    \n",
    "    processed_df = None\n",
    "    \n",
    "    try:\n",
    "        processed_df = load_and_preprocess_data(\n",
    "            file_path=config['paths']['raw_data_file'],\n",
    "            text_source_columns=config['data_source']['text_source_columns'],\n",
    "            unique_id_column=config['data_source']['unique_id_column'],\n",
    "            required_columns_for_docs_creation=config['data_source']['required_columns_for_docs_creation'],\n",
    "            dropped_rows_output_path=config['paths']['dropped_rows_output_file'],\n",
    "            data_type_specific_df_processing=config['data_source']['data_type_specific_df_processing'],\n",
    "            clean_apply_unescape=config['preprocessing']['cleaning']['apply_unescape'],\n",
    "            clean_apply_url_removal=config['preprocessing']['cleaning']['apply_url_removal'],\n",
    "            clean_apply_html_tag_removal=config['preprocessing']['cleaning']['apply_html_tag_removal'],\n",
    "            clean_apply_quote_normalization=config['preprocessing']['cleaning']['apply_quote_normalization'],\n",
    "            clean_apply_char_filtering=config['preprocessing']['cleaning']['apply_char_filtering'],\n",
    "            clean_char_filter_regex=config['preprocessing']['cleaning']['char_filter_regex'],\n",
    "            clean_apply_html_entity_removal=config['preprocessing']['cleaning']['apply_html_entity_removal'],\n",
    "            clean_apply_lowercase=config['preprocessing']['cleaning']['apply_lowercase'],\n",
    "            apply_length_filter=config['preprocessing']['filters']['apply_length_filter'],\n",
    "            min_doc_length=config['preprocessing']['filters']['min_doc_length'],\n",
    "            max_doc_length=config['preprocessing']['filters']['max_doc_length'],\n",
    "            apply_duplicate_removal=config['preprocessing']['filters']['apply_duplicate_removal'],\n",
    "            column_for_duplicate_checking=config['preprocessing']['filters']['column_for_duplicate_checking'],\n",
    "            apply_score_filter=config['preprocessing']['filters']['apply_score_filter'],\n",
    "            score_column_for_filtering=config['preprocessing']['filters']['score_column_for_filtering'],\n",
    "            min_score_for_filtering=config['preprocessing']['filters']['min_score_for_filtering'],\n",
    "            max_score_for_filtering=config['preprocessing']['filters']['max_score_for_filtering']\n",
    "        )\n",
    "    \n",
    "        if processed_df is not None:\n",
    "            logging.info(f\"Preprocessing finished. Processed DataFrame shape: {processed_df.shape}\")\n",
    "            if not processed_df.empty:\n",
    "                try:\n",
    "                    output_dir = os.path.dirname(config['paths']['processed_data_output_file'])\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                        logging.info(f\"Created output directory: {output_dir}\")\n",
    "                    processed_df.to_csv(config['paths']['processed_data_output_file'], index=False)\n",
    "                    logging.info(f\"Processed DataFrame saved to: {config['paths']['processed_data_output_file']}\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error saving processed DataFrame: {e}\")\n",
    "            else:\n",
    "                logging.info(\"Processed DataFrame is empty, not saving main output file.\")\n",
    "        else:\n",
    "            logging.warning(\"Preprocessing did not return a DataFrame.\")\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"Input file path error: {e}. Please ensure the path is correct in your config file.\")\n",
    "    except KeyError as e:\n",
    "        logging.error(f\"Configuration error: Missing key {e}. Please check your config file.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred during preprocessing: {e}\", exc_info=True)\n",
    "else:\n",
    "    logging.error(\"Configuration not loaded. Cannot run preprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9940ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Main Processed DataFrame --- \n",
      "\n",
      "Processed DataFrame Info (g:\\BERTopic_Modeling\\data/processed/IFS_test_processed.csv):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112156 entries, 0 to 112155\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   id                     112156 non-null  object \n",
      " 1   link_id                112156 non-null  object \n",
      " 2   author                 112156 non-null  object \n",
      " 3   created_utc            112156 non-null  float64\n",
      " 4   subreddit              112156 non-null  object \n",
      " 5   body                   112156 non-null  object \n",
      " 6   score                  112156 non-null  int64  \n",
      " 7   all_awardings          112155 non-null  object \n",
      " 8   gildings               112156 non-null  object \n",
      " 9   total_awards_received  112155 non-null  float64\n",
      " 10  author_flair_text      0 non-null       float64\n",
      " 11  author_flair_richtext  108899 non-null  object \n",
      "dtypes: float64(3), int64(1), object(8)\n",
      "memory usage: 10.3+ MB\n",
      "\n",
      "First 5 rows of processed data:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "link_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_utc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "all_awardings",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "gildings",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total_awards_received",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "author_flair_text",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "author_flair_richtext",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "0d807bcf-c4ae-4570-8aaa-6cb9ed4256de",
       "rows": [
        [
         "0",
         "efgpylf",
         "t3_ah7kd8",
         "hubblekeat",
         "1548962227.0",
         "InternalFamilySystems",
         "Hey there, I hope others can chime in and offer their view points, but here's mine:\n\nFor context, I started IFS after my primary care doctor recommended it to me. I had been through about 15 other doctors trying to find the source of my physical pain or fibromyalgia or whatever.\n\n1] I definitely feel like my parts are different from me. In my therapy, before we delve into parts work we usually would do a meditation to focus on the Self, basically, who I really am without all the parts driving the bus. I have a part who looks like my grandpa, some are just feelings, some are located in my body, some to the side, some are memories. They're very fluid for me...\n\n2] I have a part of me that likes to act out in order to be comforted, and the way it acts out is usually bad... I realized that I really hated this part of myself and wish I could cut it out of me. During a therapy session though I realized that this part was actually trying to help me, it just didn't know how to act. I, from a place of Self (and not from the other part of me that hates it), had to reach out to this part and give it the love and attention it was seeking. Getting back to your question, I used to feel like I could cut parts out of me that I didn't like, but I've come to realize that there's something they want me to know or learn before they're willing to give back control to Me, the Self.\n\n3] Yes, I don't remember all the parts from my therapy session. My therapist keeps track of them in notes just in case one comes back or we need to work with one over multiple sessions, but I usually forget them once I've made peace with them. Some linger, like my Grandfather part, but others go dormant, split into even more parts, recombine, or otherwise... I don't feel it's necessary to keep tabs on all of them, just the ones seeking attention from me.\n\n4] It was pretty rough detaching myself from some parts that I really enjoyed, but knew were holding me back. I am Christian, and my faith has played a large role for me in recovery. IFS seems to share a lot in common with Buddhism, which I find fascinating... \"Unfulfilled Parts\" could be analogous to \"Neuroses\", I need to research more, though. For my viewpoint, my Self is who I truly am as a literal spirit son of Heavenly Father, with all my infinite potential. The force helping to resolve and bring together my Self with my Parts is possible through Jesus Christ's Atonement, which was done to allow us to become At-one with ourselves, Heavenly Father, and those we love. (This is just my personal view, though. Other views aren't more right or wrong, this is just my... working hypothesis. :) )\n\n5] I don't feel I've explored this concept enough to comment on it. I feel that the experiences of our childhood can create parts that continue to affect us, especially traumatic ones or ones with strong negative memories. My therapist would sometimes ask how old a part thought I was. Then if there was a discrepancy, she asked me if it wanted me to see anything from the past or have anything changed about the memories. I feel this is a major way IFS can help with PTSD, and was extremely liberating for me... As far as multiple inner children, for me I don't know.\n\n6] Do you feel that way, or is there a part that feels that way? It might be worth it to explore this concept with your parts further once you're in a good place of Self. I don't feel as tied to my inner child as you seem to be, which is maybe something I should work on... The parts that are having these feelings of disconnect or yearning for how your inner child feels may be the ones to tell you what you can do to improve that.\n\n7] My parts have had different genders, but it seems that mine are much more abstract than yours. My parts definitely have different goals, and when they differ from my Self or from other parts that's where the conflict comes in. But for the most part, my Parts are pretty abstract... Sometimes a person, sometimes a thought, floating orb, place in my body, thoughts, etc.\n\nThese were great questions that helped me quantify what I've been working on. Thanks for asking them! Best wishes to you, your health, and your relationships with your parts. :)\n\n[EDIT] Answered the rest of the questions. I saved the comment since it was getting long, not realizing that was the submit button... D'oh!",
         "1",
         null,
         "{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}",
         null,
         null,
         "[]"
        ],
        [
         "1",
         "ej34hly",
         "t3_b3yw8m",
         "[deleted]",
         "1553218073.0",
         "InternalFamilySystems",
         "[removed]",
         "1",
         "[]",
         "{}",
         "0.0",
         null,
         null
        ],
        [
         "2",
         "ejvolcw",
         "t3_b7t3o6",
         "NervousGuidance",
         "1554133298.0",
         "InternalFamilySystems",
         "I'd recommend \"Self-Therapy\" by Jay Earley. It's written to be very accessible and Jay is a great writer who has dedicated his career to IFS. \n\nSelf-Therapy: A Step-By-Step Guide to Creating Wholeness and Healing Your Inner Child Using IFS, A New, Cutting-Edge Psychotherapy, 2nd Edition https://www.amazon.com/dp/0984392777/ref=cm_sw_r_cp_apa_i_AdJOCbPSJ1R2J",
         "2",
         "[]",
         "{}",
         "0.0",
         null,
         "[]"
        ],
        [
         "3",
         "ejvq37d",
         "t3_b7t3o6",
         "coquitam",
         "1554134373.0",
         "InternalFamilySystems",
         "Thank you, this looks good, just what I hoped to find. ",
         "1",
         "[]",
         "{}",
         "0.0",
         null,
         "[]"
        ],
        [
         "4",
         "ejvqitv",
         "t3_b7t3o6",
         "NervousGuidance",
         "1554134695.0",
         "InternalFamilySystems",
         "You're welcome!",
         "1",
         "[]",
         "{}",
         "0.0",
         null,
         "[]"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>gildings</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efgpylf</td>\n",
       "      <td>t3_ah7kd8</td>\n",
       "      <td>hubblekeat</td>\n",
       "      <td>1.548962e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>Hey there, I hope others can chime in and offe...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ej34hly</td>\n",
       "      <td>t3_b3yw8m</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1.553218e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ejvolcw</td>\n",
       "      <td>t3_b7t3o6</td>\n",
       "      <td>NervousGuidance</td>\n",
       "      <td>1.554133e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>I'd recommend \"Self-Therapy\" by Jay Earley. It...</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ejvq37d</td>\n",
       "      <td>t3_b7t3o6</td>\n",
       "      <td>coquitam</td>\n",
       "      <td>1.554134e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>Thank you, this looks good, just what I hoped ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ejvqitv</td>\n",
       "      <td>t3_b7t3o6</td>\n",
       "      <td>NervousGuidance</td>\n",
       "      <td>1.554135e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>You're welcome!</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    link_id           author   created_utc              subreddit  \\\n",
       "0  efgpylf  t3_ah7kd8       hubblekeat  1.548962e+09  InternalFamilySystems   \n",
       "1  ej34hly  t3_b3yw8m        [deleted]  1.553218e+09  InternalFamilySystems   \n",
       "2  ejvolcw  t3_b7t3o6  NervousGuidance  1.554133e+09  InternalFamilySystems   \n",
       "3  ejvq37d  t3_b7t3o6         coquitam  1.554134e+09  InternalFamilySystems   \n",
       "4  ejvqitv  t3_b7t3o6  NervousGuidance  1.554135e+09  InternalFamilySystems   \n",
       "\n",
       "                                                body  score all_awardings  \\\n",
       "0  Hey there, I hope others can chime in and offe...      1           NaN   \n",
       "1                                          [removed]      1            []   \n",
       "2  I'd recommend \"Self-Therapy\" by Jay Earley. It...      2            []   \n",
       "3  Thank you, this looks good, just what I hoped ...      1            []   \n",
       "4                                    You're welcome!      1            []   \n",
       "\n",
       "                               gildings  total_awards_received  \\\n",
       "0  {'gid_1': 0, 'gid_2': 0, 'gid_3': 0}                    NaN   \n",
       "1                                    {}                    0.0   \n",
       "2                                    {}                    0.0   \n",
       "3                                    {}                    0.0   \n",
       "4                                    {}                    0.0   \n",
       "\n",
       "   author_flair_text author_flair_richtext  \n",
       "0                NaN                    []  \n",
       "1                NaN                   NaN  \n",
       "2                NaN                    []  \n",
       "3                NaN                    []  \n",
       "4                NaN                    []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output file should be at: g:\\BERTopic_Modeling\\data/processed/IFS_test_processed.csv\n",
      "Does output file exist? True\n",
      "\n",
      "--- Dropped Rows (due to missing required columns) --- \n",
      "Dropped rows file not found at: g:\\BERTopic_Modeling\\data/processed/IFS_test_dropped.csv. This is expected if no rows were dropped.\n"
     ]
    }
   ],
   "source": [
    "# ## 4. Inspect Output\n",
    "\n",
    "from IPython.display import display \n",
    "\n",
    "print(\"--- Main Processed DataFrame --- \")\n",
    "if 'processed_df' in locals() and processed_df is not None and not processed_df.empty:\n",
    "    # Use the path from the config dictionary\n",
    "    output_file_path = config['paths']['processed_data_output_file']\n",
    "    dropped_rows_path = config['paths']['dropped_rows_output_file']\n",
    "\n",
    "    print(f\"\\nProcessed DataFrame Info ({output_file_path}):\")\n",
    "    processed_df.info()\n",
    "    print(\"\\nFirst 5 rows of processed data:\")\n",
    "    display(processed_df.head())\n",
    "    if 'docs' in processed_df.columns:\n",
    "        print(\"\\nSample of 'docs' column (first 3 documents):\")\n",
    "        for i, doc in enumerate(processed_df['docs'].head(3)):\n",
    "            print(f\"Doc {i+1}: {doc[:200]}...\") \n",
    "    print(f\"\\nOutput file should be at: {output_file_path}\")\n",
    "    print(f\"Does output file exist? {os.path.exists(output_file_path)}\")\n",
    "\n",
    "elif 'processed_df' in locals() and processed_df is not None and processed_df.empty:\n",
    "     print(\"\\nPreprocessing resulted in an empty DataFrame. Check filters and source data.\")\n",
    "     # Use the path from the config dictionary\n",
    "     output_file_path = config['paths']['processed_data_output_file']\n",
    "     print(f\"Output file path specified: {output_file_path}\")\n",
    "     print(f\"Does (potentially empty) output file exist? {os.path.exists(output_file_path)}\")\n",
    "else:\n",
    "    print(\"\\nPreprocessing failed or DataFrame was not created/returned correctly.\")\n",
    "    # Use the path from the config dictionary\n",
    "    if 'config' in locals() and config:\n",
    "        print(f\"Expected output file: {config['paths']['processed_data_output_file']}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Dropped Rows (due to missing required columns) --- \")\n",
    "# Use the path from the config dictionary\n",
    "dropped_rows_path = config['paths']['dropped_rows_output_file']\n",
    "if os.path.exists(dropped_rows_path):\n",
    "    try:\n",
    "        df_dropped_check = pd.read_csv(dropped_rows_path)\n",
    "        print(f\"Successfully loaded dropped rows file: {dropped_rows_path}\")\n",
    "        print(f\"Number of rows dropped due to missing required columns: {len(df_dropped_check)}\")\n",
    "        if not df_dropped_check.empty:\n",
    "            print(\"\\nFirst 5 rows of dropped data:\")\n",
    "            display(df_dropped_check.head())\n",
    "        else:\n",
    "            print(\"The dropped rows file is empty.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or inspecting dropped rows file {dropped_rows_path}: {e}\")\n",
    "else:\n",
    "    print(f\"Dropped rows file not found at: {dropped_rows_path}. This is expected if no rows were dropped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
