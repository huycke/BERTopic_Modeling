{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16b270e",
   "metadata": {},
   "source": [
    "Notebook 01: Data Preprocessing\n",
    "\n",
    "This notebook tests the `load_and_preprocess_data` function from `src.preprocessing`.\n",
    "It loads raw data, applies cleaning/unitization based on a configuration,\n",
    "and saves the processed output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e2f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK 'wordnet' data package...\n",
      "Downloading NLTK 'omw-1.4' data package (needed for wordnet)...\n",
      "NLTK downloads attempted.\n",
      "\n",
      "NLTK data paths searched:\n",
      "['C:\\\\Users\\\\snake/nltk_data', 'g:\\\\BERTopic_Modeling\\\\.venv\\\\nltk_data', 'g:\\\\BERTopic_Modeling\\\\.venv\\\\share\\\\nltk_data', 'g:\\\\BERTopic_Modeling\\\\.venv\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\snake\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\snake\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\snake\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "# --- Attempt to bypass SSL verification issues if they occur ---\n",
    "# (Sometimes needed on corporate networks or specific setups)\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "# --- End SSL bypass ---\n",
    "\n",
    "print(\"Downloading NLTK 'wordnet' data package...\")\n",
    "nltk.download('wordnet')\n",
    "print(\"Downloading NLTK 'omw-1.4' data package (needed for wordnet)...\")\n",
    "nltk.download('omw-1.4') # Often required by wordnet\n",
    "print(\"NLTK downloads attempted.\")\n",
    "\n",
    "# Optional: Verify download path (for debugging)\n",
    "print(\"\\nNLTK data paths searched:\")\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b54f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported preprocessing functions.\n"
     ]
    }
   ],
   "source": [
    "# ## 1. Imports and Setup\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# --- Add src directory to Python path ---\n",
    "# This allows importing modules from src. Adjust path if notebook is moved.\n",
    "module_path = os.path.abspath(os.path.join('..')) # Assumes notebook is in 'notebooks/' dir\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# --- Import the preprocessing function ---\n",
    "try:\n",
    "    from src.preprocessing import load_and_preprocess_data\n",
    "    from src.utils import load_config # Optional: if using YAML config file\n",
    "    print(\"Successfully imported preprocessing functions.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing functions: {e}\")\n",
    "    print(\"Ensure the 'src' directory is in the Python path and files exist.\")\n",
    "\n",
    "# --- Configure Logging ---\n",
    "# Basic logging setup for notebook visibility\n",
    "# Use force=True to allow reconfiguring logging in Jupyter environment\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fc4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2. Define Configuration\n",
    "\n",
    "# Option A: Define configuration directly as a dictionary\n",
    "# -----------------------------------------------------\n",
    "# !!! CONFIGURATION FOR A COMMENTS CSV FILE !!!\n",
    "\n",
    "# Assumes paths are relative to the PROJECT ROOT (BERTopic_Modeling),\n",
    "# NOT relative to the notebook itself.\n",
    "raw_data_file = 'G:/BERTopic_Modeling/data/raw/IFS_test.csv' # Your comments file\n",
    "processed_data_output_file = 'G:/BERTopic_Modeling/data/processed/IFS_comments_processed_docs.csv' # Output file\n",
    "\n",
    "# Define parameters specifically for the comments file structure\n",
    "preprocessing_params = {\n",
    "    'column_mapping': {\n",
    "        'input_id_col': 'id',           # ID column in comments CSV\n",
    "        'input_text_cols': ['body'],    # *** Use 'body' column for text ***\n",
    "        'output_id_col': 'doc_id',      # Standard name in output\n",
    "        'output_text_col': 'text'       # Standard name for text after processing\n",
    "    },\n",
    "    # Adjust metadata to keep based on comments CSV columns\n",
    "    'metadata_cols': ['created_utc', 'score', 'subreddit', 'link_id', 'author', 'author_flair_text'],\n",
    "    'skip_missing_essential': True,     # Skips rows if 'id' or 'body' is missing/empty\n",
    "    'cleaning_options': {               # Keep cleaning options consistent for now\n",
    "        'html_unescape': True,\n",
    "        'remove_urls': True,\n",
    "        'remove_emails': True,\n",
    "        'lowercase': True,\n",
    "        'boilerplate_remove': [r'\\[deleted\\]', r'\\[removed\\]'],\n",
    "        'custom_regex_remove': [],\n",
    "        'remove_punctuation': False,\n",
    "        'remove_stop_words': False,\n",
    "        'lemmatize': False\n",
    "    },\n",
    "    'granularity': 'document',          # Process whole comments for this example\n",
    "    'filtering_options': {\n",
    "        'min_char_length': 20,          # Allow potentially shorter comments\n",
    "        'metadata_filters': [\n",
    "            {'column': 'score', 'condition': '> 0'} # Filter comments with score > 0 (example)\n",
    "        ],\n",
    "        'deduplicate_exact': True       # Remove exact duplicate comments\n",
    "    },\n",
    "    'force_recompute': False            # Set to True to ignore cache and rerun\n",
    "}\n",
    "\n",
    "# --- (Optional) Print the config to verify ---\n",
    "# import json\n",
    "# print(\"Using preprocessing parameters:\")\n",
    "# print(json.dumps(preprocessing_params, indent=2))\n",
    "\n",
    "\n",
    "# Option B: Load configuration from a YAML file (Recommended for complex runs)\n",
    "# -------------------------------------------------------------------------\n",
    "# config_yaml_path = '../configs/preprocessing_config.yaml' # Path relative to notebook\n",
    "# # Make sure the path below is relative to project root if utils.py uses relative paths\n",
    "# config_yaml_path_for_load = 'configs/preprocessing_config.yaml'\n",
    "# try:\n",
    "#     preprocessing_params = load_config(config_yaml_path_for_load)\n",
    "#     # Add/override file paths if they are not in the YAML\n",
    "#     # raw_data_file = preprocessing_params.get('input_file', 'data/raw/default.csv')\n",
    "#     # processed_data_output_file = preprocessing_params.get('output_file', 'data/processed/default_processed.csv')\n",
    "#     logging.info(f\"Loaded config from {config_yaml_path_for_load}\")\n",
    "# except FileNotFoundError:\n",
    "#     logging.error(f\"Config file not found: {config_yaml_path_for_load}. Using dictionary definition (Option A).\")\n",
    "#     # Fallback to Option A parameters defined above if file not found\n",
    "# except NameError:\n",
    "#      logging.error(f\"load_config function not imported correctly. Using dictionary definition (Option A).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1bc2a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 17:50:24,800 - INFO - Input file: G:/BERTopic_Modeling/data/raw/IFS_test.csv\n",
      "2025-05-04 17:50:24,800 - INFO - Output file: G:/BERTopic_Modeling/data/processed/IFS_comments_processed_docs.csv\n",
      "2025-05-04 17:50:24,801 - INFO - Starting preprocessing for: G:/BERTopic_Modeling/data/raw/IFS_test.csv\n",
      "2025-05-04 17:50:24,801 - INFO - Loading raw data from: G:/BERTopic_Modeling/data/raw/IFS_test.csv\n",
      "2025-05-04 17:50:25,354 - INFO - Standardizing column names...\n",
      "2025-05-04 17:50:25,369 - INFO - Combining text columns...\n",
      "2025-05-04 17:50:25,385 - INFO - Handling missing essential data...\n",
      "2025-05-04 17:50:25,418 - INFO - Applying text cleaning...\n",
      "2025-05-04 17:50:28,262 - INFO - Text cleaning applied.\n",
      "2025-05-04 17:50:28,262 - INFO - Unitizing text based on granularity...\n",
      "2025-05-04 17:50:28,262 - INFO - Applying granularity: document\n",
      "2025-05-04 17:50:28,277 - INFO - Applying filtering...\n",
      "2025-05-04 17:50:28,327 - INFO - Identified 7499 rows to remove based on: char_len<20\n",
      "2025-05-04 17:50:56,493 - INFO - Identified 1279 rows to remove based on: metadata_filter:(`score` > 0)\n",
      "2025-05-04 17:51:01,044 - INFO - Identified 482 rows to remove based on: exact_duplicate_text\n",
      "2025-05-04 17:51:02,726 - INFO - Filtering complete. Final row count: 102896 (Removed 9260 rows in total).\n",
      "2025-05-04 17:51:02,726 - INFO - Saving processed data to: G:/BERTopic_Modeling/data/processed/IFS_comments_processed_docs.csv\n",
      "2025-05-04 17:51:03,346 - INFO - Successfully saved processed data (102896 rows).\n",
      "2025-05-04 17:51:03,359 - INFO - Successfully saved removal log (9260 rows) to: G:/BERTopic_Modeling/data/processed\\IFS_comments_processed_docs_removal_log.csv\n",
      "2025-05-04 17:51:03,379 - INFO - Preprocessing finished.\n"
     ]
    }
   ],
   "source": [
    "# ## 3. Run Preprocessing\n",
    "\n",
    "logging.info(f\"Input file: {raw_data_file}\")\n",
    "logging.info(f\"Output file: {processed_data_output_file}\")\n",
    "\n",
    "# Ensure the parameters dictionary is defined (from Cell 2)\n",
    "if 'preprocessing_params' not in locals():\n",
    "    raise NameError(\"preprocessing_params dictionary not defined. Please run Cell 2 first.\")\n",
    "\n",
    "# Initialize variable to store result\n",
    "processed_df = None\n",
    "\n",
    "try:\n",
    "    # Call the main preprocessing function\n",
    "    # Note: file paths are passed relative to where the function *runs* from\n",
    "    # (usually the project root if you start jupyter from there)\n",
    "    processed_df = load_and_preprocess_data(\n",
    "        file_path=raw_data_file,\n",
    "        output_path=processed_data_output_file,\n",
    "        **preprocessing_params # Unpack the dictionary as keyword arguments\n",
    "        # Or pass config_path=config_yaml_path_for_load if using Option B from Cell 2\n",
    "    )\n",
    "\n",
    "    logging.info(\"Preprocessing finished.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(f\"Input/Output file path error: {e}\")\n",
    "    logging.error(f\"Please ensure the paths are correct relative to the project root directory.\")\n",
    "except ValueError as e:\n",
    "    logging.error(f\"Configuration or data error: {e}\")\n",
    "except NameError as e:\n",
    "     logging.error(f\"Import error - required function not loaded: {e}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"An unexpected error occurred during preprocessing: {e}\", exc_info=True) # Show traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9940ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed DataFrame Info (G:/BERTopic_Modeling/data/processed/IFS_comments_processed_docs.csv):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 102896 entries, 0 to 112155\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   doc_id             102896 non-null  object \n",
      " 1   unit_id            102896 non-null  object \n",
      " 2   text_unit          102896 non-null  object \n",
      " 3   link_id            102896 non-null  object \n",
      " 4   author             102896 non-null  object \n",
      " 5   created_utc        102896 non-null  float64\n",
      " 6   subreddit          102896 non-null  object \n",
      " 7   score              102896 non-null  int64  \n",
      " 8   author_flair_text  0 non-null       float64\n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 7.9+ MB\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "doc_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unit_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text_unit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "link_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_utc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "author_flair_text",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9c2dda53-5d7b-45f7-8ae1-a858169c83f2",
       "rows": [
        [
         "0",
         "efgpylf",
         "efgpylf",
         "hey there, i hope others can chime in and offer their view points, but here's mine: for context, i started ifs after my primary care doctor recommended it to me. i had been through about 15 other doctors trying to find the source of my physical pain or fibromyalgia or whatever. 1] i definitely feel like my parts are different from me. in my therapy, before we delve into parts work we usually would do a meditation to focus on the self, basically, who i really am without all the parts driving the bus. i have a part who looks like my grandpa, some are just feelings, some are located in my body, some to the side, some are memories. they're very fluid for me... 2] i have a part of me that likes to act out in order to be comforted, and the way it acts out is usually bad... i realized that i really hated this part of myself and wish i could cut it out of me. during a therapy session though i realized that this part was actually trying to help me, it just didn't know how to act. i, from a place of self (and not from the other part of me that hates it), had to reach out to this part and give it the love and attention it was seeking. getting back to your question, i used to feel like i could cut parts out of me that i didn't like, but i've come to realize that there's something they want me to know or learn before they're willing to give back control to me, the self. 3] yes, i don't remember all the parts from my therapy session. my therapist keeps track of them in notes just in case one comes back or we need to work with one over multiple sessions, but i usually forget them once i've made peace with them. some linger, like my grandfather part, but others go dormant, split into even more parts, recombine, or otherwise... i don't feel it's necessary to keep tabs on all of them, just the ones seeking attention from me. 4] it was pretty rough detaching myself from some parts that i really enjoyed, but knew were holding me back. i am christian, and my faith has played a large role for me in recovery. ifs seems to share a lot in common with buddhism, which i find fascinating... \"unfulfilled parts\" could be analogous to \"neuroses\", i need to research more, though. for my viewpoint, my self is who i truly am as a literal spirit son of heavenly father, with all my infinite potential. the force helping to resolve and bring together my self with my parts is possible through jesus christ's atonement, which was done to allow us to become at-one with ourselves, heavenly father, and those we love. (this is just my personal view, though. other views aren't more right or wrong, this is just my... working hypothesis. :) ) 5] i don't feel i've explored this concept enough to comment on it. i feel that the experiences of our childhood can create parts that continue to affect us, especially traumatic ones or ones with strong negative memories. my therapist would sometimes ask how old a part thought i was. then if there was a discrepancy, she asked me if it wanted me to see anything from the past or have anything changed about the memories. i feel this is a major way ifs can help with ptsd, and was extremely liberating for me... as far as multiple inner children, for me i don't know. 6] do you feel that way, or is there a part that feels that way? it might be worth it to explore this concept with your parts further once you're in a good place of self. i don't feel as tied to my inner child as you seem to be, which is maybe something i should work on... the parts that are having these feelings of disconnect or yearning for how your inner child feels may be the ones to tell you what you can do to improve that. 7] my parts have had different genders, but it seems that mine are much more abstract than yours. my parts definitely have different goals, and when they differ from my self or from other parts that's where the conflict comes in. but for the most part, my parts are pretty abstract... sometimes a person, sometimes a thought, floating orb, place in my body, thoughts, etc. these were great questions that helped me quantify what i've been working on. thanks for asking them! best wishes to you, your health, and your relationships with your parts. :) [edit] answered the rest of the questions. i saved the comment since it was getting long, not realizing that was the submit button... d'oh!",
         "t3_ah7kd8",
         "hubblekeat",
         "1548962227.0",
         "InternalFamilySystems",
         "1",
         null
        ],
        [
         "2",
         "ejvolcw",
         "ejvolcw",
         "i'd recommend \"self-therapy\" by jay earley. it's written to be very accessible and jay is a great writer who has dedicated his career to ifs. self-therapy: a step-by-step guide to creating wholeness and healing your inner child using ifs, a new, cutting-edge psychotherapy, 2nd edition",
         "t3_b7t3o6",
         "NervousGuidance",
         "1554133298.0",
         "InternalFamilySystems",
         "2",
         null
        ],
        [
         "3",
         "ejvq37d",
         "ejvq37d",
         "thank you, this looks good, just what i hoped to find.",
         "t3_b7t3o6",
         "coquitam",
         "1554134373.0",
         "InternalFamilySystems",
         "1",
         null
        ],
        [
         "5",
         "el9kmpr",
         "el9kmpr",
         "hi i am currently in therapy with an ifs therapist. i have a fair amount of other therapeutic approaches, most bodywork based but also accessing exiled/frozen/lost parts. i have found the direct communication and recognition of the parts to be incredibly helpful. yes, fear may come up - but remember it is always another part, trying to protect something. sometimes as we begin to explore inside it triggers those protectors - and fear can be one of their tools. the recommendation is that talking to protector parts is ok, but one should never try to work with the exiled parts (that the protectors are protecting) without a therapist there, as if they are not skillfully dealt with they can become harder to work with in future. hope this helps a little!",
         "t3_ah0w3y",
         "sparkerson",
         "1555681480.0",
         "InternalFamilySystems",
         "2",
         null
        ],
        [
         "6",
         "emxhvez",
         "emxhvez",
         "here's one: he's got some good youtube videos on ifs as well:",
         "t3_blratl",
         "NervousGuidance",
         "1557417728.0",
         "InternalFamilySystems",
         "2",
         null
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>text_unit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>author_flair_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efgpylf</td>\n",
       "      <td>efgpylf</td>\n",
       "      <td>hey there, i hope others can chime in and offe...</td>\n",
       "      <td>t3_ah7kd8</td>\n",
       "      <td>hubblekeat</td>\n",
       "      <td>1.548962e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ejvolcw</td>\n",
       "      <td>ejvolcw</td>\n",
       "      <td>i'd recommend \"self-therapy\" by jay earley. it...</td>\n",
       "      <td>t3_b7t3o6</td>\n",
       "      <td>NervousGuidance</td>\n",
       "      <td>1.554133e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ejvq37d</td>\n",
       "      <td>ejvq37d</td>\n",
       "      <td>thank you, this looks good, just what i hoped ...</td>\n",
       "      <td>t3_b7t3o6</td>\n",
       "      <td>coquitam</td>\n",
       "      <td>1.554134e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>el9kmpr</td>\n",
       "      <td>el9kmpr</td>\n",
       "      <td>hi i am currently in therapy with an ifs thera...</td>\n",
       "      <td>t3_ah0w3y</td>\n",
       "      <td>sparkerson</td>\n",
       "      <td>1.555681e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>emxhvez</td>\n",
       "      <td>emxhvez</td>\n",
       "      <td>here's one: he's got some good youtube videos ...</td>\n",
       "      <td>t3_blratl</td>\n",
       "      <td>NervousGuidance</td>\n",
       "      <td>1.557418e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id  unit_id                                          text_unit  \\\n",
       "0  efgpylf  efgpylf  hey there, i hope others can chime in and offe...   \n",
       "2  ejvolcw  ejvolcw  i'd recommend \"self-therapy\" by jay earley. it...   \n",
       "3  ejvq37d  ejvq37d  thank you, this looks good, just what i hoped ...   \n",
       "5  el9kmpr  el9kmpr  hi i am currently in therapy with an ifs thera...   \n",
       "6  emxhvez  emxhvez  here's one: he's got some good youtube videos ...   \n",
       "\n",
       "     link_id           author   created_utc              subreddit  score  \\\n",
       "0  t3_ah7kd8       hubblekeat  1.548962e+09  InternalFamilySystems      1   \n",
       "2  t3_b7t3o6  NervousGuidance  1.554133e+09  InternalFamilySystems      2   \n",
       "3  t3_b7t3o6         coquitam  1.554134e+09  InternalFamilySystems      1   \n",
       "5  t3_ah0w3y       sparkerson  1.555681e+09  InternalFamilySystems      2   \n",
       "6  t3_blratl  NervousGuidance  1.557418e+09  InternalFamilySystems      2   \n",
       "\n",
       "   author_flair_text  \n",
       "0                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "5                NaN  \n",
       "6                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "doc_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unit_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text_unit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "link_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_utc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "author_flair_text",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d7d493a2-1be7-4e75-82e8-beb075d3c498",
       "rows": [
        [
         "112151",
         "m4rn4i9",
         "m4rn4i9",
         "this 💯 over and over. it's a tool and a map but not the territory",
         "t3_1hqoub5",
         "leaninletgo",
         "1735686275.0",
         "InternalFamilySystems",
         "23",
         null
        ],
        [
         "112152",
         "m4rnfq9",
         "m4rnfq9",
         "“i agree with you—it’s not for everyone. however, this modality transformed everything for my system. cbt was ineffective for me, and i stayed with it far too long. what truly helped was the non-pathologizing and destigmatizing approach of internal family systems (ifs). for those who need the diagnostic labeling ingrained in western mental health, it can be difficult to embrace the paradigm shift that ifs offers. because ifs was such an effective healing tool for my mental system, i pursued the arduous lottery process to become a level 2 practitioner now working towards certification. i now use this model not only for myself but also for my clients.”",
         "t3_1hqoub5",
         "SoteEmpathHealer",
         "1735686398.0",
         "InternalFamilySystems",
         "18",
         null
        ],
        [
         "112153",
         "m4rnxjn",
         "m4rnxjn",
         "i had a hard time remembering things from childhood. ifs naturally led to memories emerging as i dialogued with parts.",
         "t3_1hj8ylf",
         "iwillmeetyou",
         "1735686593.0",
         "InternalFamilySystems",
         "2",
         null
        ],
        [
         "112154",
         "m4rr6vv",
         "m4rr6vv",
         "somatics is a very personal thing. you need to work with someone for that person to track you and give you interventions. it comes in the form of unconscious or conscious body movements, gestures, impulses, sensations and more. i dont think you can get much out of doing it yourself.",
         "t3_1hqmbf0",
         "Blissful524",
         "1735687840.0",
         "InternalFamilySystems",
         "8",
         null
        ],
        [
         "112155",
         "m4rvkep",
         "m4rvkep",
         "i found it really helpful to read the book somatic ifs by susan mcconnell, like another comment said. but i was already working with a practitioner who draws from both ifs and somatic approaches. i feel like it would have all sounded a little abstract to me if i wasn't already doing somatic parts work. i had previously tried to read peter levine to learn about somatic experiencing, but i found it hard to get a sense of what somatic work actually looked like just from that. his books like waking the tiger and freedom from pain were a little more useful to me because they have experiential exercises you can do to get acquainted with your body and its sensations. it also helped me to watch videos of peter levine talking, especially when he gives case examples from therapy or demonstrates exercises. some other things that helped me personally were practicing yoga to develop a more detailed and subtle connection to my body and working through books about sexual trauma that bring a somatic therapy focus to the topic and have practical exercises too (e.g. reclaiming pleasure by holly richmond and healing sexual trauma workbook by erika shershun). really the best thing to do if you can alongside your own research is to find someone who practices somatic experiencing, sensorimotor psychotherapy, somatic parts work, yoga therapy, etc. and work with them. i have found somatic work really hard to do alone and some of the books i mentioned were too emotionally difficult for me to read before i started with my current therapist.",
         "t3_1hqmbf0",
         "Miserable_News975",
         "1735689499.0",
         "InternalFamilySystems",
         "5",
         null
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>text_unit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>author_flair_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112151</th>\n",
       "      <td>m4rn4i9</td>\n",
       "      <td>m4rn4i9</td>\n",
       "      <td>this 💯 over and over. it's a tool and a map bu...</td>\n",
       "      <td>t3_1hqoub5</td>\n",
       "      <td>leaninletgo</td>\n",
       "      <td>1.735686e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112152</th>\n",
       "      <td>m4rnfq9</td>\n",
       "      <td>m4rnfq9</td>\n",
       "      <td>“i agree with you—it’s not for everyone. howev...</td>\n",
       "      <td>t3_1hqoub5</td>\n",
       "      <td>SoteEmpathHealer</td>\n",
       "      <td>1.735686e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112153</th>\n",
       "      <td>m4rnxjn</td>\n",
       "      <td>m4rnxjn</td>\n",
       "      <td>i had a hard time remembering things from chil...</td>\n",
       "      <td>t3_1hj8ylf</td>\n",
       "      <td>iwillmeetyou</td>\n",
       "      <td>1.735687e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112154</th>\n",
       "      <td>m4rr6vv</td>\n",
       "      <td>m4rr6vv</td>\n",
       "      <td>somatics is a very personal thing. you need to...</td>\n",
       "      <td>t3_1hqmbf0</td>\n",
       "      <td>Blissful524</td>\n",
       "      <td>1.735688e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112155</th>\n",
       "      <td>m4rvkep</td>\n",
       "      <td>m4rvkep</td>\n",
       "      <td>i found it really helpful to read the book som...</td>\n",
       "      <td>t3_1hqmbf0</td>\n",
       "      <td>Miserable_News975</td>\n",
       "      <td>1.735689e+09</td>\n",
       "      <td>InternalFamilySystems</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         doc_id  unit_id                                          text_unit  \\\n",
       "112151  m4rn4i9  m4rn4i9  this 💯 over and over. it's a tool and a map bu...   \n",
       "112152  m4rnfq9  m4rnfq9  “i agree with you—it’s not for everyone. howev...   \n",
       "112153  m4rnxjn  m4rnxjn  i had a hard time remembering things from chil...   \n",
       "112154  m4rr6vv  m4rr6vv  somatics is a very personal thing. you need to...   \n",
       "112155  m4rvkep  m4rvkep  i found it really helpful to read the book som...   \n",
       "\n",
       "           link_id             author   created_utc              subreddit  \\\n",
       "112151  t3_1hqoub5        leaninletgo  1.735686e+09  InternalFamilySystems   \n",
       "112152  t3_1hqoub5   SoteEmpathHealer  1.735686e+09  InternalFamilySystems   \n",
       "112153  t3_1hj8ylf       iwillmeetyou  1.735687e+09  InternalFamilySystems   \n",
       "112154  t3_1hqmbf0        Blissful524  1.735688e+09  InternalFamilySystems   \n",
       "112155  t3_1hqmbf0  Miserable_News975  1.735689e+09  InternalFamilySystems   \n",
       "\n",
       "        score  author_flair_text  \n",
       "112151     23                NaN  \n",
       "112152     18                NaN  \n",
       "112153      2                NaN  \n",
       "112154      8                NaN  \n",
       "112155      5                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check if output file exists: True\n"
     ]
    }
   ],
   "source": [
    "# ## 4. Inspect Output\n",
    "\n",
    "# Check if the DataFrame was loaded/created and inspect it\n",
    "if 'processed_df' in locals() and isinstance(processed_df, pd.DataFrame) and not processed_df.empty:\n",
    "    print(f\"\\nProcessed DataFrame Info ({processed_data_output_file}):\")\n",
    "    # Use display() in Jupyter/VSCode notebooks for better table rendering\n",
    "    from IPython.display import display\n",
    "    processed_df.info()\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(processed_df.head())\n",
    "    print(\"\\nLast 5 rows:\")\n",
    "    display(processed_df.tail())\n",
    "    print(f\"\\nCheck if output file exists: {os.path.exists(processed_data_output_file)}\")\n",
    "elif 'processed_df' in locals() and isinstance(processed_df, pd.DataFrame) and processed_df.empty:\n",
    "     print(\"\\nPreprocessing resulted in an empty DataFrame.\")\n",
    "     print(f\"\\nCheck if empty output file exists: {os.path.exists(processed_data_output_file)}\")\n",
    "else:\n",
    "    print(\"\\nPreprocessing failed or DataFrame not created/returned correctly.\")\n",
    "    # Check if the output file was created anyway (e.g., if caching worked but function failed later)\n",
    "    if os.path.exists(processed_data_output_file):\n",
    "         print(f\"Output file exists at {processed_data_output_file}, but DataFrame wasn't returned to notebook.\")\n",
    "    else:\n",
    "         print(f\"Output file {processed_data_output_file} does not exist.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
